{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Domain Synonyms\n",
    "This note book is used for identifying and grouping domain synonyms in book reviews for each book. The approach relies on creating an `nltk.context` per book which will be used to compare only nouns. Nouns that appear to have a highly similar context, will be grouped together under the same name (either the one's or the other's). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For monitoring duration of pandas processes\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# To avoid RuntimeError: Set changed size during iteration\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm_gui`, `tqdm_notebook`, optional kwargs, etc.)\n",
    "tqdm.pandas(desc=\"Progress:\")\n",
    "\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "# can also groupby:\n",
    "# df.groupby(0).progress_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>['timeless', ' gibran', ' backs', ' content', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN##000100039X</td>\n",
       "      <td>[' prophet', ' kahlil', ' gibran', ' thirty', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3##000100039X</td>\n",
       "      <td>[' first', ' books', ' recall', ' collection',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65##000100039X</td>\n",
       "      <td>['prophet', ' kahlil', ' work', ' world', ' mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV##000100039X</td>\n",
       "      <td>['gibran', ' khalil', ' gibran', ' born', ' on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    uniqueKey  \\\n",
       "0  A2XQ5LZHTD4AFT##000100039X   \n",
       "1   AF7CSSGV93RXN##000100039X   \n",
       "2  A1NPNGWBVD9AK3##000100039X   \n",
       "3  A3IS4WGMFR4X65##000100039X   \n",
       "4   AWLFVCT9128JV##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  ['timeless', ' gibran', ' backs', ' content', ...  \n",
       "1  [' prophet', ' kahlil', ' gibran', ' thirty', ...  \n",
       "2  [' first', ' books', ' recall', ' collection',...  \n",
       "3  ['prophet', ' kahlil', ' work', ' world', ' mi...  \n",
       "4  ['gibran', ' khalil', ' gibran', ' born', ' on...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df0 = pd.read_csv(\"../data/interim/002_keyed_nouns.csv\", sep=\"\\t\", low_memory=False)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert back to a string list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 582711/582711 [00:10<00:00, 57162.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [timeless,   gibran,   backs,   content,   mea...\n",
       "1    [ prophet,   kahlil,   gibran,   thirty,   yea...\n",
       "2    [ first,   books,   recall,   collection,   gi...\n",
       "3    [prophet,   kahlil,   work,   world,   million...\n",
       "4    [gibran,   khalil,   gibran,   born,   one tho...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text_to_list(review):\n",
    "    return review.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"\\t\",\"\").split(\",\")\n",
    "\n",
    "# Convert \"reviewText\" field to back to list\n",
    "df0['reviewText'] = df0['reviewText'].astype(str)\n",
    "df0['reviewText'] = df0['reviewText'].progress_apply(lambda text: convert_text_to_list(text));\n",
    "df0['reviewText'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split unique key to `asin` and `unserId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId        asin\n",
       "0  A2XQ5LZHTD4AFT  000100039X\n",
       "1   AF7CSSGV93RXN  000100039X\n",
       "2  A1NPNGWBVD9AK3  000100039X\n",
       "3  A3IS4WGMFR4X65  000100039X\n",
       "4   AWLFVCT9128JV  000100039X"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(df0.uniqueKey.str.split('##',1).tolist(),columns = ['userId','asin'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[timeless,   gibran,   backs,   content,   mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ prophet,   kahlil,   gibran,   thirty,   yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ first,   books,   recall,   collection,   gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[prophet,   kahlil,   work,   world,   million...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gibran,   khalil,   gibran,   born,   one tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  [timeless,   gibran,   backs,   content,   mea...\n",
       "1  [ prophet,   kahlil,   gibran,   thirty,   yea...\n",
       "2  [ first,   books,   recall,   collection,   gi...\n",
       "3  [prophet,   kahlil,   work,   world,   million...\n",
       "4  [gibran,   khalil,   gibran,   born,   one tho..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviewText = pd.DataFrame(df0['reviewText'])\n",
    "df_reviewText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dataframe with `userId`, `asin` and `reviewText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_new = pd.concat([df1, df_reviewText], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[timeless,   gibran,   backs,   content,   mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[ prophet,   kahlil,   gibran,   thirty,   yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[ first,   books,   recall,   collection,   gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[prophet,   kahlil,   work,   world,   million...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[gibran,   khalil,   gibran,   born,   one tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId        asin  \\\n",
       "0  A2XQ5LZHTD4AFT  000100039X   \n",
       "1   AF7CSSGV93RXN  000100039X   \n",
       "2  A1NPNGWBVD9AK3  000100039X   \n",
       "3  A3IS4WGMFR4X65  000100039X   \n",
       "4   AWLFVCT9128JV  000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  [timeless,   gibran,   backs,   content,   mea...  \n",
       "1  [ prophet,   kahlil,   gibran,   thirty,   yea...  \n",
       "2  [ first,   books,   recall,   collection,   gi...  \n",
       "3  [prophet,   kahlil,   work,   world,   million...  \n",
       "4  [gibran,   khalil,   gibran,   born,   one tho...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `userId` and groupby the same book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_books = df_new.drop(columns=['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|█████████▉| 59324/59325 [00:05<00:00, 10588.68it/s]\n"
     ]
    }
   ],
   "source": [
    "df_books_bigReviews = df_books.groupby(['asin'])['reviewText'].progress_apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[[timeless,   gibran,   backs,   content,   me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002051850</td>\n",
       "      <td>[[ book,   takes,   civil,   war,   descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002113570</td>\n",
       "      <td>[[ book,   great,   woman,   done,   great,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002117088</td>\n",
       "      <td>[[ renoir,   father,   quot,   bedside,   surg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000215725X</td>\n",
       "      <td>[[ dalrymple,   great,   apetite,   context,  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                         reviewText\n",
       "0  000100039X  [[timeless,   gibran,   backs,   content,   me...\n",
       "1  0002051850  [[ book,   takes,   civil,   war,   descriptio...\n",
       "2  0002113570  [[ book,   great,   woman,   done,   great,   ...\n",
       "3  0002117088  [[ renoir,   father,   quot,   bedside,   surg...\n",
       "4  000215725X  [[ dalrymple,   great,   apetite,   context,  ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books_bigReviews_df = pd.DataFrame(df_books_bigReviews).reset_index()\n",
    "df_books_bigReviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def merge_list(reviewsList):\n",
    "    new_list = []\n",
    "    for review in reviewsList:\n",
    "        new_list = new_list + review\n",
    "    return list(set(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 59324/59324 [00:04<00:00, 11900.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "asin\n",
       "000100039X    [  earlier,   attention,   melody,   came,   n...\n",
       "0002051850    [  beer,   jordon,   italy,   quot,   lean,   ...\n",
       "0002113570    [  level,   actions,   attention,   work,   su...\n",
       "0002117088    [  rough,   image,   index,   none,   quot,   ...\n",
       "000215725X    [  alive,   interviews,   gather,   introduces...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books_bigReviews_single_list_df = df_books_bigReviews.progress_apply(lambda reviewsList: merge_list(reviewsList))\n",
    "df_books_bigReviews_single_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>[  earlier,   attention,   melody,   came,   n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002051850</td>\n",
       "      <td>[  beer,   jordon,   italy,   quot,   lean,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002113570</td>\n",
       "      <td>[  level,   actions,   attention,   work,   su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002117088</td>\n",
       "      <td>[  rough,   image,   index,   none,   quot,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000215725X</td>\n",
       "      <td>[  alive,   interviews,   gather,   introduces...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                         reviewText\n",
       "0  000100039X  [  earlier,   attention,   melody,   came,   n...\n",
       "1  0002051850  [  beer,   jordon,   italy,   quot,   lean,   ...\n",
       "2  0002113570  [  level,   actions,   attention,   work,   su...\n",
       "3  0002117088  [  rough,   image,   index,   none,   quot,   ...\n",
       "4  000215725X  [  alive,   interviews,   gather,   introduces..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books_vs_bigreviews = pd.DataFrame(df_books_bigReviews_single_list_df).reset_index()\n",
    "df_books_vs_bigreviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_books_vs_bigreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2.reviewText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/chadjinik/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import product\n",
    "\n",
    "def get_synonyms_dict(bigReview, theta):\n",
    "    \n",
    "    synonyms = {}\n",
    "    \n",
    "    for i in range(len(bigReview)):\n",
    "        wordx = bigReview[i]\n",
    "        for j in range(i,len(bigReview)):\n",
    "            wordy = bigReview[j]\n",
    "            \n",
    "            # don't compare with the same word\n",
    "            if(wordx == wordy):\n",
    "                continue\n",
    "            \n",
    "            sem1, sem2 = wn.synsets(wordx), wn.synsets(wordy)\n",
    "            prod = list(product(*[sem1,sem2]))\n",
    "            \n",
    "            maxscore = 0.0\n",
    "            for k,l in prod:\n",
    "                score = k.wup_similarity(l) # Wu-Palmer Similarity\n",
    "                if score is not None:\n",
    "                    if maxscore < score:\n",
    "                        maxscore = score\n",
    "            \n",
    "            if maxscore > theta and wordy not in synonyms:\n",
    "                synonyms[wordx] = wordy\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point onwards computation needs increase dramatically, so I will reduce the dataset I am using to just keep in 1000/59324 books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress::   0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Progress::   0%|          | 2/1000 [00:11<1:33:55,  5.65s/it]\u001b[A\n",
      "Progress::   0%|          | 3/1000 [00:36<3:10:58, 11.49s/it]\u001b[A\n",
      "Progress::   0%|          | 4/1000 [00:36<2:15:09,  8.14s/it]\u001b[A\n",
      "Progress::   0%|          | 5/1000 [00:37<1:36:07,  5.80s/it]\u001b[A\n",
      "Progress::   1%|          | 6/1000 [00:41<1:28:24,  5.34s/it]\u001b[A\n",
      "Progress::   1%|          | 7/1000 [00:49<1:40:48,  6.09s/it]\u001b[A\n",
      "Progress::   1%|          | 8/1000 [00:51<1:19:49,  4.83s/it]\u001b[A\n",
      "Progress::   1%|          | 9/1000 [00:52<1:01:30,  3.72s/it]\u001b[A\n",
      "Progress::   1%|          | 10/1000 [01:20<3:01:05, 10.98s/it]\u001b[A\n",
      "Progress::   1%|          | 11/1000 [01:24<2:29:37,  9.08s/it]\u001b[A\n",
      "Progress::   1%|          | 12/1000 [01:26<1:54:56,  6.98s/it]\u001b[A\n",
      "Progress::   1%|▏         | 13/1000 [01:27<1:24:46,  5.15s/it]\u001b[A\n",
      "Progress::   1%|▏         | 14/1000 [01:28<1:00:53,  3.71s/it]\u001b[A\n",
      "Progress::   2%|▏         | 15/1000 [01:28<45:18,  2.76s/it]  \u001b[A\n",
      "Progress::   2%|▏         | 16/1000 [01:44<1:47:51,  6.58s/it]\u001b[A\n",
      "Progress::   2%|▏         | 17/1000 [01:46<1:29:12,  5.44s/it]\u001b[A\n",
      "Progress::   2%|▏         | 18/1000 [01:47<1:03:27,  3.88s/it]\u001b[A\n",
      "Progress::   2%|▏         | 19/1000 [01:47<47:44,  2.92s/it]  \u001b[A\n",
      "Progress::   2%|▏         | 20/1000 [01:57<1:19:48,  4.89s/it]\u001b[A\n",
      "Progress::   2%|▏         | 21/1000 [01:57<58:42,  3.60s/it]  \u001b[A\n",
      "Progress::   2%|▏         | 22/1000 [02:03<1:10:01,  4.30s/it]\u001b[A\n",
      "Progress::   2%|▏         | 23/1000 [02:06<1:01:29,  3.78s/it]\u001b[A\n",
      "Progress::   2%|▏         | 24/1000 [02:07<48:31,  2.98s/it]  \u001b[A\n",
      "Progress::   2%|▎         | 25/1000 [02:08<37:54,  2.33s/it]\u001b[A\n",
      "Progress::   3%|▎         | 26/1000 [02:08<28:18,  1.74s/it]\u001b[A\n",
      "Progress::   3%|▎         | 27/1000 [02:09<23:58,  1.48s/it]\u001b[A\n",
      "Progress::   3%|▎         | 28/1000 [02:10<19:58,  1.23s/it]\u001b[A\n",
      "Progress::   3%|▎         | 29/1000 [02:11<19:02,  1.18s/it]\u001b[A\n",
      "Progress::   3%|▎         | 30/1000 [02:12<17:20,  1.07s/it]\u001b[A\n",
      "Progress::   3%|▎         | 31/1000 [02:13<19:48,  1.23s/it]\u001b[A\n",
      "Progress::   3%|▎         | 32/1000 [02:20<46:50,  2.90s/it]\u001b[A\n",
      "Progress::   3%|▎         | 33/1000 [02:23<48:16,  2.99s/it]\u001b[A\n",
      "Progress::   3%|▎         | 34/1000 [02:25<40:07,  2.49s/it]\u001b[A\n",
      "Progress::   4%|▎         | 35/1000 [02:32<1:06:29,  4.13s/it]\u001b[A\n",
      "Progress::   4%|▎         | 36/1000 [02:36<1:02:38,  3.90s/it]\u001b[A\n",
      "Progress::   4%|▎         | 37/1000 [02:41<1:07:53,  4.23s/it]\u001b[A\n",
      "Progress::   4%|▍         | 38/1000 [02:41<48:17,  3.01s/it]  \u001b[A\n",
      "Progress::   4%|▍         | 39/1000 [02:58<1:57:43,  7.35s/it]\u001b[A\n",
      "Progress::   4%|▍         | 40/1000 [03:00<1:29:51,  5.62s/it]\u001b[A\n",
      "Progress::   4%|▍         | 41/1000 [03:00<1:03:19,  3.96s/it]\u001b[A\n",
      "Progress::   4%|▍         | 42/1000 [03:02<53:24,  3.34s/it]  \u001b[A\n",
      "Progress::   4%|▍         | 43/1000 [03:04<45:49,  2.87s/it]\u001b[A\n",
      "Progress::   4%|▍         | 44/1000 [03:08<53:24,  3.35s/it]\u001b[A\n",
      "Progress::   4%|▍         | 45/1000 [03:12<55:23,  3.48s/it]\u001b[A\n",
      "Progress::   5%|▍         | 46/1000 [03:13<41:36,  2.62s/it]\u001b[A\n",
      "Progress::   5%|▍         | 47/1000 [03:15<38:03,  2.40s/it]\u001b[A\n",
      "Progress::   5%|▍         | 48/1000 [03:15<29:20,  1.85s/it]\u001b[A\n",
      "Progress::   5%|▍         | 49/1000 [03:21<46:06,  2.91s/it]\u001b[A\n",
      "Progress::   5%|▌         | 50/1000 [03:22<40:18,  2.55s/it]\u001b[A\n",
      "Progress::   5%|▌         | 51/1000 [03:28<54:05,  3.42s/it]\u001b[A\n",
      "Progress::   5%|▌         | 52/1000 [03:30<49:02,  3.10s/it]\u001b[A\n",
      "Progress::   5%|▌         | 53/1000 [03:30<36:00,  2.28s/it]\u001b[A\n",
      "Progress::   5%|▌         | 54/1000 [03:34<44:08,  2.80s/it]\u001b[A\n",
      "Progress::   6%|▌         | 55/1000 [03:39<53:31,  3.40s/it]\u001b[A\n",
      "Progress::   6%|▌         | 56/1000 [03:43<57:26,  3.65s/it]\u001b[A\n",
      "Progress::   6%|▌         | 57/1000 [04:10<2:43:50, 10.42s/it]\u001b[A\n",
      "Progress::   6%|▌         | 58/1000 [04:11<2:02:59,  7.83s/it]\u001b[A\n",
      "Progress::   6%|▌         | 59/1000 [04:14<1:35:38,  6.10s/it]\u001b[A\n",
      "Progress::   6%|▌         | 60/1000 [04:28<2:14:49,  8.61s/it]\u001b[A\n",
      "Progress::   6%|▌         | 61/1000 [04:30<1:45:51,  6.76s/it]\u001b[A\n",
      "Progress::   6%|▌         | 62/1000 [04:33<1:26:49,  5.55s/it]\u001b[A\n",
      "Progress::   6%|▋         | 63/1000 [04:35<1:11:12,  4.56s/it]\u001b[A\n",
      "Progress::   6%|▋         | 64/1000 [04:36<53:17,  3.42s/it]  \u001b[A\n",
      "Progress::   6%|▋         | 65/1000 [04:37<40:04,  2.57s/it]\u001b[A\n",
      "Progress::   7%|▋         | 66/1000 [04:44<1:03:24,  4.07s/it]\u001b[A\n",
      "Progress::   7%|▋         | 67/1000 [04:47<57:30,  3.70s/it]  \u001b[A\n",
      "Progress::   7%|▋         | 68/1000 [04:51<1:00:00,  3.86s/it]\u001b[A\n",
      "Progress::   7%|▋         | 69/1000 [04:57<1:07:17,  4.34s/it]\u001b[A\n",
      "Progress::   7%|▋         | 70/1000 [04:58<50:18,  3.25s/it]  \u001b[A\n",
      "Progress::   7%|▋         | 71/1000 [04:58<37:03,  2.39s/it]\u001b[A\n",
      "Progress::   7%|▋         | 72/1000 [05:02<43:14,  2.80s/it]\u001b[A\n",
      "Progress::   7%|▋         | 73/1000 [05:02<33:02,  2.14s/it]\u001b[A\n",
      "Progress::   7%|▋         | 74/1000 [05:04<29:16,  1.90s/it]\u001b[A\n",
      "Progress::   8%|▊         | 75/1000 [05:07<34:44,  2.25s/it]\u001b[A\n",
      "Progress::   8%|▊         | 76/1000 [05:07<26:22,  1.71s/it]\u001b[A\n",
      "Progress::   8%|▊         | 77/1000 [05:08<23:59,  1.56s/it]\u001b[A\n",
      "Progress::   8%|▊         | 78/1000 [05:11<28:11,  1.83s/it]\u001b[A\n",
      "Progress::   8%|▊         | 79/1000 [05:13<28:41,  1.87s/it]\u001b[A\n",
      "Progress::   8%|▊         | 80/1000 [05:17<41:41,  2.72s/it]\u001b[A\n",
      "Progress::   8%|▊         | 81/1000 [05:27<1:12:37,  4.74s/it]\u001b[A\n",
      "Progress::   8%|▊         | 82/1000 [05:33<1:19:03,  5.17s/it]\u001b[A\n",
      "Progress::   8%|▊         | 83/1000 [05:36<1:09:45,  4.56s/it]\u001b[A\n",
      "Progress::   8%|▊         | 84/1000 [05:39<1:02:30,  4.09s/it]\u001b[A\n",
      "Progress::   8%|▊         | 85/1000 [06:05<2:42:33, 10.66s/it]\u001b[A\n",
      "Progress::   9%|▊         | 86/1000 [06:07<2:03:08,  8.08s/it]\u001b[A\n",
      "Progress::   9%|▊         | 87/1000 [06:10<1:38:04,  6.45s/it]\u001b[A\n",
      "Progress::   9%|▉         | 88/1000 [06:14<1:28:43,  5.84s/it]\u001b[A\n",
      "Progress::   9%|▉         | 89/1000 [06:16<1:10:25,  4.64s/it]\u001b[A\n",
      "Progress::   9%|▉         | 90/1000 [06:17<52:01,  3.43s/it]  \u001b[A\n",
      "Progress::   9%|▉         | 91/1000 [06:34<1:54:46,  7.58s/it]\u001b[A\n",
      "Progress::   9%|▉         | 92/1000 [06:38<1:36:50,  6.40s/it]\u001b[A\n",
      "Progress::   9%|▉         | 93/1000 [06:45<1:41:01,  6.68s/it]\u001b[A\n",
      "Progress::   9%|▉         | 94/1000 [06:46<1:13:22,  4.86s/it]\u001b[A\n",
      "Progress::  10%|▉         | 95/1000 [06:46<54:44,  3.63s/it]  \u001b[A\n",
      "Progress::  10%|▉         | 96/1000 [06:50<52:20,  3.47s/it]\u001b[A\n",
      "Progress::  10%|▉         | 97/1000 [06:50<38:23,  2.55s/it]\u001b[A\n",
      "Progress::  10%|▉         | 98/1000 [07:10<1:55:31,  7.68s/it]\u001b[A\n",
      "Progress::  10%|▉         | 99/1000 [07:11<1:26:45,  5.78s/it]\u001b[A\n",
      "Progress::  10%|█         | 100/1000 [07:11<1:03:06,  4.21s/it]\u001b[A\n",
      "Progress::  10%|█         | 101/1000 [07:13<50:13,  3.35s/it]  \u001b[A\n",
      "Progress::  10%|█         | 102/1000 [07:14<40:58,  2.74s/it]\u001b[A\n",
      "Progress::  10%|█         | 103/1000 [07:14<29:12,  1.95s/it]\u001b[A\n",
      "Progress::  10%|█         | 104/1000 [07:20<44:50,  3.00s/it]\u001b[A\n",
      "Progress::  10%|█         | 105/1000 [07:22<39:34,  2.65s/it]\u001b[A\n",
      "Progress::  11%|█         | 106/1000 [07:24<39:51,  2.67s/it]\u001b[A\n",
      "Progress::  11%|█         | 107/1000 [07:35<1:16:30,  5.14s/it]\u001b[A\n",
      "Progress::  11%|█         | 108/1000 [07:40<1:16:57,  5.18s/it]\u001b[A\n",
      "Progress::  11%|█         | 109/1000 [07:44<1:08:08,  4.59s/it]\u001b[A\n",
      "Progress::  11%|█         | 110/1000 [07:45<55:10,  3.72s/it]  \u001b[A\n",
      "Progress::  11%|█         | 111/1000 [07:49<53:35,  3.62s/it]\u001b[A\n",
      "Progress::  11%|█         | 112/1000 [07:49<40:14,  2.72s/it]\u001b[A\n",
      "Progress::  11%|█▏        | 113/1000 [07:55<55:15,  3.74s/it]\u001b[A\n",
      "Progress::  11%|█▏        | 114/1000 [07:58<48:01,  3.25s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 115/1000 [08:01<49:35,  3.36s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 116/1000 [08:02<40:31,  2.75s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 117/1000 [08:16<1:26:35,  5.88s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 118/1000 [08:33<2:18:19,  9.41s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 119/1000 [08:40<2:04:00,  8.45s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 120/1000 [08:53<2:27:16, 10.04s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 121/1000 [08:59<2:08:50,  8.79s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 122/1000 [09:00<1:32:36,  6.33s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 123/1000 [09:08<1:39:19,  6.80s/it]\u001b[A\n",
      "Progress::  12%|█▏        | 124/1000 [09:11<1:24:56,  5.82s/it]\u001b[A\n",
      "Progress::  12%|█▎        | 125/1000 [09:12<1:03:30,  4.36s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  13%|█▎        | 126/1000 [09:14<52:39,  3.61s/it]  \u001b[A\n",
      "Progress::  13%|█▎        | 127/1000 [09:14<37:47,  2.60s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 128/1000 [09:15<31:53,  2.19s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 129/1000 [09:18<34:28,  2.38s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 130/1000 [09:28<1:07:11,  4.63s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 131/1000 [09:42<1:48:15,  7.48s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 132/1000 [09:46<1:31:35,  6.33s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 133/1000 [09:48<1:11:49,  4.97s/it]\u001b[A\n",
      "Progress::  13%|█▎        | 134/1000 [09:58<1:33:40,  6.49s/it]\u001b[A\n",
      "Progress::  14%|█▎        | 135/1000 [10:01<1:19:30,  5.51s/it]\u001b[A\n",
      "Progress::  14%|█▎        | 136/1000 [10:10<1:33:12,  6.47s/it]\u001b[A\n",
      "Progress::  14%|█▎        | 137/1000 [10:11<1:09:47,  4.85s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 138/1000 [10:11<50:09,  3.49s/it]  \u001b[A\n",
      "Progress::  14%|█▍        | 139/1000 [10:27<1:43:43,  7.23s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 140/1000 [10:30<1:24:32,  5.90s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 141/1000 [10:55<2:46:14, 11.61s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 142/1000 [11:11<3:06:37, 13.05s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 143/1000 [11:18<2:39:46, 11.19s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 144/1000 [11:19<1:56:55,  8.20s/it]\u001b[A\n",
      "Progress::  14%|█▍        | 145/1000 [11:29<2:02:35,  8.60s/it]\u001b[A\n",
      "Progress::  15%|█▍        | 146/1000 [11:31<1:34:59,  6.67s/it]\u001b[A\n",
      "Progress::  15%|█▍        | 147/1000 [11:32<1:09:51,  4.91s/it]\u001b[A\n",
      "Progress::  15%|█▍        | 148/1000 [11:59<2:43:38, 11.52s/it]\u001b[A\n",
      "Progress::  15%|█▍        | 149/1000 [12:00<2:00:07,  8.47s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Get Synonym Dicts per Book Reviews\n",
    "df3 = df2[0:1000].assign(synDict = df2['reviewText'][0:1000].progress_apply(lambda big_review: get_synonyms_dict(big_review, 0.9)))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(columns=['reviewText'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.merge(df_new[0:1000], df4, how='inner', on='asin')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "matrix_m01 = df5.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    new_list = []\n",
    "    for word in matrix_m01[i][2]:\n",
    "        clean_word = word.replace(\" \", \"\");\n",
    "        if clean_word in matrix_m01[i][3].keys():\n",
    "            new_list.append(matrix_m01[i][3][clean_word])\n",
    "        else:\n",
    "            new_list.append(clean_word)\n",
    "    matrix_m01[i][2] =  new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(matrix_m01)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns = ['userId','asin', 'reviewText', 'synDict']\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_final.drop(columns=['synDict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../data/interim/004_synonyms_grouped_1k.csv\", sep='\\t', header=True, index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_final.to_pickle(\"../data/interim/004_synonyms_grouped_1k.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# END OF FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
